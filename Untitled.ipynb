{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6821cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307f6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fer2013.csv') #Reading the FER2013 dataset\n",
    "data = data[data['emotion']!=1] #Kicking disgust out\n",
    "new_emo_num_map = {0: 0, 2: 2, 3: 3, 4: 4, 5: 5, 6: 1} #remapping as 6 to 1\n",
    "data['emotion'] = data['emotion'].map(new_emo_num_map)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e19223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angry</td>\n",
       "      <td>4953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fear</td>\n",
       "      <td>5121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sad</td>\n",
       "      <td>6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>8989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Surprise</td>\n",
       "      <td>4002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion  number\n",
       "0     Angry    4953\n",
       "1      Fear    5121\n",
       "2       Sad    6077\n",
       "3   Neutral    6198\n",
       "4     Happy    8989\n",
       "5  Surprise    4002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_map = {0: 'Angry', 1: 'Neutral', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise'}\n",
    "emotion_counts = data['emotion'].value_counts(sort = False).reset_index()\n",
    "emotion_counts.columns = ['emotion', 'number']\n",
    "emotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\n",
    "\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e74abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Emotional Status')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "# print('\\n')\n",
    "sns.barplot(emotion_counts.emotion, emotion_counts.number)\n",
    "plt.title('Class distribution')\n",
    "plt.ylabel('Number of Sample')\n",
    "plt.xlabel('Emotional Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaeebcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRNO(df):\n",
    "    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n",
    "    #pixel_sequence = df['pixels']\n",
    "    #df['pixels'] = [int(pixel) for pixel in pixel_sequence.split()]\n",
    "    data_X = np.array(df['pixels'].tolist(), dtype = 'float32').reshape(-1, width, height, 1)/255.0\n",
    "    data_Y = to_categorical(df['emotion'], num_classes)\n",
    "    return data_X, data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2df5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(featurewise_center = False,\n",
    "                                    featurewise_std_normalization = False,\n",
    "                                    rotation_range = 20,\n",
    "                                    width_shift_range = 0.2,\n",
    "                                    height_shift_range = 0.2,\n",
    "                                    zoom_range = 0.1,\n",
    "                                    horizontal_flip = True)\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 20, mode = 'min', restore_best_weights = True)\n",
    "# es = EarlyStopping(monitor = 'val_accuracy', patience = 30, mode = 'max', restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcc028ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6 #Disgust out\n",
    "width, height = 48, 48\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "num_features = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d032416",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcecfab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['KFold'] = range(len(data))\n",
    "data['KFold'] = data['KFold']%fold_number\n",
    "data.drop('Usage', inplace= True, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9edd859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 48, 48, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 48, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 24,580,678\n",
      "Trainable params: 24,572,870\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "441/441 [==============================] - 36s 73ms/step - loss: 2.0854 - accuracy: 0.2079 - val_loss: 1.7769 - val_accuracy: 0.2453 2\n",
      "Epoch 2/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.8367 - accuracy: 0.2257 - val_loss: 1.6945 - val_accuracy: 0.2701\n",
      "Epoch 3/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.7687 - accuracy: 0.2432 - val_loss: 1.6599 - val_accuracy: 0.3083\n",
      "Epoch 4/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.7037 - accuracy: 0.2886 - val_loss: 1.6171 - val_accuracy: 0.3527\n",
      "Epoch 5/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.6213 - accuracy: 0.3345 - val_loss: 1.6133 - val_accuracy: 0.3506\n",
      "Epoch 6/50\n",
      "441/441 [==============================] - 32s 72ms/step - loss: 1.5332 - accuracy: 0.3778 - val_loss: 1.4629 - val_accuracy: 0.4202\n",
      "Epoch 7/50\n",
      "441/441 [==============================] - 31s 71ms/step - loss: 1.4732 - accuracy: 0.4146 - val_loss: 1.2746 - val_accuracy: 0.4972\n",
      "Epoch 8/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.4104 - accuracy: 0.4416 - val_loss: 1.2379 - val_accuracy: 0.5229\n",
      "Epoch 9/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.3538 - accuracy: 0.4668 - val_loss: 1.2068 - val_accuracy: 0.5400\n",
      "Epoch 10/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.3112 - accuracy: 0.4906 - val_loss: 1.1626 - val_accuracy: 0.5439\n",
      "Epoch 11/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.2765 - accuracy: 0.5076 - val_loss: 1.0950 - val_accuracy: 0.5758\n",
      "Epoch 12/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.2412 - accuracy: 0.5198 - val_loss: 1.1948 - val_accuracy: 0.5467\n",
      "Epoch 13/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.2073 - accuracy: 0.5362 - val_loss: 1.1528 - val_accuracy: 0.5620 1.209 - ETA: 1s\n",
      "Epoch 14/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.1747 - accuracy: 0.5503 - val_loss: 1.0736 - val_accuracy: 0.5828\n",
      "Epoch 15/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.1553 - accuracy: 0.5594 - val_loss: 1.1104 - val_accuracy: 0.5569\n",
      "Epoch 16/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.1327 - accuracy: 0.5682 - val_loss: 1.0940 - val_accuracy: 0.5787\n",
      "Epoch 17/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.1187 - accuracy: 0.5764 - val_loss: 1.1122 - val_accuracy: 0.5723\n",
      "Epoch 18/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.0994 - accuracy: 0.5829 - val_loss: 1.0020 - val_accuracy: 0.6111\n",
      "Epoch 19/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.0846 - accuracy: 0.5868 - val_loss: 1.1250 - val_accuracy: 0.5584\n",
      "Epoch 20/50\n",
      "441/441 [==============================] - 32s 72ms/step - loss: 1.0701 - accuracy: 0.5946 - val_loss: 1.1105 - val_accuracy: 0.5737\n",
      "Epoch 21/50\n",
      "441/441 [==============================] - 31s 71ms/step - loss: 1.0562 - accuracy: 0.6028 - val_loss: 1.0503 - val_accuracy: 0.5910\n",
      "Epoch 22/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.0440 - accuracy: 0.6080 - val_loss: 0.9684 - val_accuracy: 0.6244\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441/441 [==============================] - 31s 71ms/step - loss: 1.0432 - accuracy: 0.6115 - val_loss: 0.9925 - val_accuracy: 0.6179\n",
      "Epoch 24/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.0260 - accuracy: 0.6163 - val_loss: 0.9875 - val_accuracy: 0.6225\n",
      "Epoch 25/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 1.0047 - accuracy: 0.6202 - val_loss: 0.9383 - val_accuracy: 0.6415\n",
      "Epoch 26/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.9991 - accuracy: 0.6285 - val_loss: 1.1152 - val_accuracy: 0.5654\n",
      "Epoch 27/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.9867 - accuracy: 0.6313 - val_loss: 0.9333 - val_accuracy: 0.6436\n",
      "Epoch 28/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.9881 - accuracy: 0.6309 - val_loss: 0.9336 - val_accuracy: 0.6442\n",
      "Epoch 29/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.9800 - accuracy: 0.6359 - val_loss: 0.9415 - val_accuracy: 0.6423\n",
      "Epoch 30/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.9644 - accuracy: 0.6369 - val_loss: 0.9280 - val_accuracy: 0.6423\n",
      "Epoch 31/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.9462 - accuracy: 0.6509 - val_loss: 1.2857 - val_accuracy: 0.5277\n",
      "Epoch 32/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.9522 - accuracy: 0.6451 - val_loss: 0.9577 - val_accuracy: 0.6370\n",
      "Epoch 33/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.9407 - accuracy: 0.6522 - val_loss: 1.1236 - val_accuracy: 0.5787\n",
      "Epoch 34/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.9364 - accuracy: 0.6531 - val_loss: 1.0106 - val_accuracy: 0.6138\n",
      "Epoch 35/50\n",
      "441/441 [==============================] - 32s 72ms/step - loss: 0.9201 - accuracy: 0.6607 - val_loss: 0.9401 - val_accuracy: 0.6474\n",
      "Epoch 36/50\n",
      "441/441 [==============================] - 32s 73ms/step - loss: 0.9169 - accuracy: 0.6616 - val_loss: 0.9991 - val_accuracy: 0.6409\n",
      "Epoch 37/50\n",
      "441/441 [==============================] - 32s 73ms/step - loss: 0.9077 - accuracy: 0.6628 - val_loss: 0.9986 - val_accuracy: 0.6286\n",
      "Epoch 38/50\n",
      "441/441 [==============================] - 32s 72ms/step - loss: 0.9063 - accuracy: 0.6647 - val_loss: 0.9372 - val_accuracy: 0.6497\n",
      "Epoch 39/50\n",
      "441/441 [==============================] - 34s 77ms/step - loss: 0.8971 - accuracy: 0.6704 - val_loss: 0.9435 - val_accuracy: 0.6474\n",
      "Epoch 40/50\n",
      "441/441 [==============================] - 33s 74ms/step - loss: 0.8840 - accuracy: 0.6731 - val_loss: 1.1322 - val_accuracy: 0.5921\n",
      "Epoch 41/50\n",
      "441/441 [==============================] - 35s 78ms/step - loss: 0.8816 - accuracy: 0.6766 - val_loss: 1.1068 - val_accuracy: 0.6010\n",
      "Epoch 42/50\n",
      "441/441 [==============================] - 37s 84ms/step - loss: 0.8727 - accuracy: 0.6786 - val_loss: 0.9985 - val_accuracy: 0.6354\n",
      "Epoch 43/50\n",
      "441/441 [==============================] - 31s 71ms/step - loss: 0.8675 - accuracy: 0.6822 - val_loss: 0.9508 - val_accuracy: 0.6501\n",
      "Epoch 44/50\n",
      "441/441 [==============================] - 32s 71ms/step - loss: 0.8612 - accuracy: 0.6809 - val_loss: 0.8818 - val_accuracy: 0.6723 ETA: 0s - loss: 0.8604 \n",
      "Epoch 45/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.8525 - accuracy: 0.6882 - val_loss: 0.9855 - val_accuracy: 0.6331\n",
      "Epoch 46/50\n",
      "441/441 [==============================] - 31s 71ms/step - loss: 0.8402 - accuracy: 0.6927 - val_loss: 1.0687 - val_accuracy: 0.6054\n",
      "Epoch 47/50\n",
      "441/441 [==============================] - 31s 70ms/step - loss: 0.8377 - accuracy: 0.6931 - val_loss: 0.9059 - val_accuracy: 0.6633\n",
      "Epoch 48/50\n",
      "441/441 [==============================] - 34s 76ms/step - loss: 0.8317 - accuracy: 0.6960 - val_loss: 0.9567 - val_accuracy: 0.6491\n",
      "Epoch 49/50\n",
      "441/441 [==============================] - 33s 75ms/step - loss: 0.8311 - accuracy: 0.6983 - val_loss: 1.1024 - val_accuracy: 0.6121\n",
      "Epoch 50/50\n",
      "441/441 [==============================] - 32s 72ms/step - loss: 0.8241 - accuracy: 0.6978 - val_loss: 0.9354 - val_accuracy: 0.6576\n",
      "221/221 [==============================] - 3s 12ms/step - loss: 0.9354 - accuracy: 0.6576\n",
      "0.6576117873191833\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scorelist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2236/2532406254.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mscorelist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;31m# Creating and saving confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scorelist' is not defined"
     ]
    }
   ],
   "source": [
    "for kf in range(fold_number):\n",
    "    data_train = data[data['KFold'] != kf].copy()\n",
    "    data_val = data[data['KFold'] == kf].copy()\n",
    "    \n",
    "    # print(data_train.shape, data_val.shape)\n",
    "    \n",
    "    train_X, train_Y = CRNO(data_train)\n",
    "    val_X, val_Y = CRNO(data_val)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    #module 1\n",
    "    model.add(Conv2D(2*num_features, kernel_size=(3, 3), padding = 'same', input_shape=((width, height, 1)), data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    #module 2\n",
    "    model.add(Conv2D(4*num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(4*num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    #module 3\n",
    "    model.add(Conv2D(8*num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(8*num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    #flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #dense 1\n",
    "    model.add(Dense(16*num_features))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #dense 2\n",
    "    model.add(Dense(16*num_features))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #dense 3\n",
    "    model.add(Dense(num_features))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), #lr= 0.001\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(data_generator.flow(train_X, train_Y, batch_size),\n",
    "                    steps_per_epoch = len(train_X) / batch_size,\n",
    "                    epochs = num_epochs,\n",
    "                    verbose = 1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data = (val_X, val_Y))\n",
    "    \n",
    "    score = model.evaluate(val_X, val_Y, verbose=1)\n",
    "    print(score[1])\n",
    "    scorelist.append(score[1])\n",
    "    \n",
    "    # Creating and saving confusion matrix\n",
    "    pred_Y=model.predict(val_X)\n",
    "    tesst_Y=np.argmax(val_Y, axis=1)\n",
    "    pred_Y=np.argmax(pred_Y,axis=1)\n",
    "    cmatrix=confusion_matrix(tesst_Y, pred_Y)\n",
    "    cmatrix = cmatrix.astype('float')/cmatrix.sum(axis=1)[:, np.newaxis]\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cmatrix, annot=True, fmt= '.2f', cmap=plt.cm.Blues)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "215cbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a9865b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "272c2d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 37s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = InceptionV3(input_shape = (250,188,3), # Shape of our images\n",
    "                                include_top = False, # Leave out the last fully connected layer\n",
    "                                weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2784855",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in pre_trained_model.layers[140:]:\n",
    "    layer.trainable = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1bd6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2255b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "np.random.seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d8dc03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pre_trained_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(6, activation='softmax', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "713d10fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 250, 188, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 124, 93, 32)  864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 124, 93, 32)  96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 124, 93, 32)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 122, 91, 32)  9216        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 122, 91, 32)  96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 122, 91, 32)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 122, 91, 64)  18432       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 122, 91, 64)  192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 122, 91, 64)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 60, 45, 64)   0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 60, 45, 80)   5120        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 60, 45, 80)   240         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 60, 45, 80)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 58, 43, 192)  138240      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 58, 43, 192)  576         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 58, 43, 192)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 28, 21, 192)  0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 21, 64)   12288       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 28, 21, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 28, 21, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 21, 48)   9216        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 21, 96)   55296       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 28, 21, 48)   144         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 28, 21, 96)   288         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 28, 21, 48)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 28, 21, 96)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 28, 21, 192)  0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 21, 64)   12288       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 21, 64)   76800       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 21, 96)   82944       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 21, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 21, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 28, 21, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 28, 21, 96)   288         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 28, 21, 32)   96          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 28, 21, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 28, 21, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 28, 21, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 28, 21, 32)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 28, 21, 256)  0           activation_23[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 28, 21, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 28, 21, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 28, 21, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 28, 21, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 28, 21, 96)   55296       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 28, 21, 48)   144         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 28, 21, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 28, 21, 48)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 28, 21, 96)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 28, 21, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 28, 21, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 28, 21, 64)   76800       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 28, 21, 96)   82944       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 28, 21, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 28, 21, 64)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 28, 21, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 28, 21, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 28, 21, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 28, 21, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 28, 21, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 28, 21, 96)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 28, 21, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 28, 21, 288)  0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 28, 21, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 28, 21, 64)   192         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 28, 21, 64)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 28, 21, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 28, 21, 96)   55296       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 28, 21, 48)   144         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 28, 21, 96)   288         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 28, 21, 48)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 28, 21, 96)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 28, 21, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 28, 21, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 28, 21, 64)   76800       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 28, 21, 96)   82944       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 28, 21, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 28, 21, 64)   192         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 28, 21, 64)   192         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 28, 21, 96)   288         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 28, 21, 64)   192         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 28, 21, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 28, 21, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 28, 21, 96)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 28, 21, 64)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 28, 21, 288)  0           activation_37[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 28, 21, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 28, 21, 64)   192         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 28, 21, 64)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 28, 21, 96)   55296       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 28, 21, 96)   288         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 28, 21, 96)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 13, 10, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 13, 10, 96)   82944       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 13, 10, 384)  1152        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 13, 10, 96)   288         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 13, 10, 384)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 13, 10, 96)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 13, 10, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 13, 10, 768)  0           activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 13, 10, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 13, 10, 128)  384         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 13, 10, 128)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 13, 10, 128)  114688      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 13, 10, 128)  384         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 13, 10, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 13, 10, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 13, 10, 128)  114688      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 13, 10, 128)  384         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 13, 10, 128)  384         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 13, 10, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 13, 10, 128)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 13, 10, 128)  114688      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 13, 10, 128)  114688      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 13, 10, 128)  384         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 13, 10, 128)  384         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 13, 10, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 13, 10, 128)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 13, 10, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 13, 10, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 13, 10, 192)  172032      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 13, 10, 192)  172032      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 13, 10, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 13, 10, 192)  576         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 13, 10, 192)  576         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 13, 10, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 13, 10, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 13, 10, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 13, 10, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 13, 10, 192)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 13, 10, 192)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 13, 10, 768)  0           activation_48[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 13, 10, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 13, 10, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 13, 10, 160)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 13, 10, 160)  179200      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 13, 10, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 13, 10, 160)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 13, 10, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 13, 10, 160)  179200      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 13, 10, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 13, 10, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 13, 10, 160)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 13, 10, 160)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 13, 10, 160)  179200      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 13, 10, 160)  179200      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 13, 10, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 13, 10, 160)  480         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 13, 10, 160)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 13, 10, 160)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 13, 10, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 13, 10, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 13, 10, 192)  215040      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 13, 10, 192)  215040      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 13, 10, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 13, 10, 192)  576         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 13, 10, 192)  576         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 13, 10, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 13, 10, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 13, 10, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 13, 10, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 13, 10, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 13, 10, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 13, 10, 768)  0           activation_58[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 13, 10, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 13, 10, 160)  480         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 13, 10, 160)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 13, 10, 160)  179200      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 13, 10, 160)  480         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 13, 10, 160)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 13, 10, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 13, 10, 160)  179200      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 13, 10, 160)  480         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 13, 10, 160)  480         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 13, 10, 160)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 13, 10, 160)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 13, 10, 160)  179200      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 13, 10, 160)  179200      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 13, 10, 160)  480         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 13, 10, 160)  480         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 13, 10, 160)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 13, 10, 160)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 13, 10, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 13, 10, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 13, 10, 192)  215040      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 13, 10, 192)  215040      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 13, 10, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 13, 10, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 13, 10, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 13, 10, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 13, 10, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 13, 10, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 13, 10, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 13, 10, 192)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 13, 10, 192)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 13, 10, 768)  0           activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 13, 10, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 13, 10, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 13, 10, 192)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 13, 10, 192)  258048      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 13, 10, 192)  576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 13, 10, 192)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 13, 10, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 13, 10, 192)  258048      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 13, 10, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 13, 10, 192)  576         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 13, 10, 192)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 13, 10, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 13, 10, 192)  258048      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 13, 10, 192)  258048      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 13, 10, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 13, 10, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 13, 10, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 13, 10, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 13, 10, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 13, 10, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 13, 10, 192)  258048      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 13, 10, 192)  258048      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 13, 10, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 13, 10, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 13, 10, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 13, 10, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 13, 10, 192)  576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 13, 10, 192)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 13, 10, 192)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 13, 10, 192)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 13, 10, 192)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 13, 10, 768)  0           activation_78[0][0]              \n",
      "                                                                 activation_81[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 13, 10, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 13, 10, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 13, 10, 192)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 13, 10, 192)  258048      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 13, 10, 192)  576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 13, 10, 192)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 13, 10, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 13, 10, 192)  258048      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 13, 10, 192)  576         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 13, 10, 192)  576         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 13, 10, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 13, 10, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 6, 4, 320)    552960      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 6, 4, 192)    331776      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 6, 4, 320)    960         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 6, 4, 192)    576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 6, 4, 320)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 6, 4, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 6, 4, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 6, 4, 1280)   0           activation_89[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 6, 4, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 6, 4, 448)    1344        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 6, 4, 448)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 6, 4, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 6, 4, 384)    1548288     activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 6, 4, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 6, 4, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 6, 4, 384)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 6, 4, 384)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 6, 4, 384)    442368      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 6, 4, 384)    442368      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 6, 4, 384)    442368      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 6, 4, 384)    442368      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 6, 4, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 6, 4, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 6, 4, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 6, 4, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 6, 4, 384)    1152        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 6, 4, 384)    1152        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 6, 4, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 6, 4, 320)    960         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 6, 4, 384)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 6, 4, 384)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 6, 4, 384)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 6, 4, 384)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 6, 4, 192)    576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 6, 4, 320)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 6, 4, 768)    0           activation_96[0][0]              \n",
      "                                                                 activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 4, 768)    0           activation_100[0][0]             \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 6, 4, 192)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 6, 4, 2048)   0           activation_94[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 6, 4, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 6, 4, 448)    1344        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 6, 4, 448)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 6, 4, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 6, 4, 384)    1548288     activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 6, 4, 384)    1152        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 6, 4, 384)    1152        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 6, 4, 384)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 6, 4, 384)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 6, 4, 384)    442368      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 6, 4, 384)    442368      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 6, 4, 384)    442368      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 6, 4, 384)    442368      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 6, 4, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 6, 4, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 6, 4, 384)    1152        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 6, 4, 384)    1152        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 6, 4, 384)    1152        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 6, 4, 384)    1152        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 6, 4, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 6, 4, 320)    960         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 6, 4, 384)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 6, 4, 384)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 6, 4, 384)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 6, 4, 384)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 6, 4, 192)    576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 6, 4, 320)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 6, 4, 768)    0           activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 4, 768)    0           activation_109[0][0]             \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 6, 4, 192)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 6, 4, 2048)   0           activation_103[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            6150        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,907,110\n",
      "Trainable params: 20,009,542\n",
      "Non-trainable params: 3,897,568\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model(pre_trained_model.input, predictions)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72215f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa1ea805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9453b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"os./model_weights.h5\", monitor='val_accuracy',\n",
    "                            save_weights_only = True, \n",
    "                            mode = 'max',\n",
    "                            verbose = 1)\n",
    "lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=3, verbose=1)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\"model.h5\", monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4beec3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, lr_reducer, checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "validation_steps = test_generator.n // test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a12717f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " input depth must be evenly divisible by filter depth: 1 vs 3\n\t [[node model/conv2d_12/Conv2D (defined at \\AppData\\Local\\Temp/ipykernel_2236/2822503823.py:1) ]] [Op:__inference_train_function_159837]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2236/2822503823.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(data_generator.flow(train_X, train_Y, batch_size),\n\u001b[0m\u001b[0;32m      2\u001b[0m                 \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  input depth must be evenly divisible by filter depth: 1 vs 3\n\t [[node model/conv2d_12/Conv2D (defined at \\AppData\\Local\\Temp/ipykernel_2236/2822503823.py:1) ]] [Op:__inference_train_function_159837]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data_generator.flow(train_X, train_Y, batch_size),\n",
    "                steps_per_epoch = len(train_X) / batch_size,\n",
    "                epochs = num_epochs,\n",
    "                verbose = 1,\n",
    "                callbacks = callbacks,\n",
    "                validation_data = (val_X, val_Y),\n",
    "                   validation_steps=len(val_X) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea15ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
