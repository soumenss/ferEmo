{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e994e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b2e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fer2013.csv') #Reading the FER2013 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b0e8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6564e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['KFold'] = range(len(data))\n",
    "data['KFold'] = data['KFold']%fold_number\n",
    "data.drop('Usage', inplace= True, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96032568",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "width, height = 48, 48\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "num_features = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18177f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angry</td>\n",
       "      <td>4953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fear</td>\n",
       "      <td>5121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sad</td>\n",
       "      <td>6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>8989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Surprise</td>\n",
       "      <td>4002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Disgust</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion  number\n",
       "0     Angry    4953\n",
       "1      Fear    5121\n",
       "2       Sad    6077\n",
       "3   Neutral    6198\n",
       "4     Happy    8989\n",
       "5  Surprise    4002\n",
       "6   Disgust     547"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_map = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "emotion_counts = data['emotion'].value_counts(sort = False).reset_index()\n",
    "emotion_counts.columns = ['emotion', 'number']\n",
    "emotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\n",
    "\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dff9dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Emotional Status')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "# print('\\n')\n",
    "sns.barplot(emotion_counts.emotion, emotion_counts.number)\n",
    "plt.title('Class distribution')\n",
    "plt.ylabel('Number of Sample')\n",
    "plt.xlabel('Emotional Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8622b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRNO(df):\n",
    "    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n",
    "    #pixel_sequence = df['pixels']\n",
    "    #df['pixels'] = [int(pixel) for pixel in pixel_sequence.split()]\n",
    "    data_X = np.array(df['pixels'].tolist(), dtype = 'float32').reshape(-1, width, height, 1)/255.0\n",
    "    data_Y = to_categorical(df['emotion'], num_classes)\n",
    "    return data_X, data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1a4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(featurewise_center = False,\n",
    "                                    featurewise_std_normalization = False,\n",
    "                                    rotation_range = 20,\n",
    "                                    width_shift_range = 0.2,\n",
    "                                    height_shift_range = 0.2,\n",
    "                                    zoom_range = 0.1,\n",
    "                                    horizontal_flip = True)\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 20, mode = 'min', restore_best_weights = True)\n",
    "# es = EarlyStopping(monitor = 'val_accuracy', patience = 30, mode = 'max', restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d88fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,498,439\n",
      "Trainable params: 2,494,855\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Conv2D (defined at \\AppData\\Local\\Temp/ipykernel_8236/330788477.py:69) ]] [Op:__inference_train_function_2865]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8236/330788477.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     history = model.fit(data_generator.flow(train_X, train_Y, batch_size),\n\u001b[0m\u001b[0;32m     70\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Conv2D (defined at \\AppData\\Local\\Temp/ipykernel_8236/330788477.py:69) ]] [Op:__inference_train_function_2865]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "for kf in range(fold_number):\n",
    "    data_train = data[data['KFold'] != kf].copy()\n",
    "    data_val = data[data['KFold'] == kf].copy()\n",
    "    \n",
    "    # print(data_train.shape, data_val.shape)\n",
    "    \n",
    "    train_X, train_Y = CRNO(data_train)\n",
    "    val_X, val_Y = CRNO(data_val)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    #module 1\n",
    "    model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), padding = 'same', input_shape=((width, height, 1)), data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    #module 2\n",
    "    model.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    #module 3\n",
    "    model.add(Conv2D(num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(num_features, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    #flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #dense 1\n",
    "    model.add(Dense(2*2*2*num_features))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #dense 2\n",
    "    model.add(Dense(2*2*num_features))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #dense 3\n",
    "    model.add(Dense(2*num_features))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(data_generator.flow(train_X, train_Y, batch_size),\n",
    "                    steps_per_epoch = len(train_X) / batch_size,\n",
    "                    epochs = num_epochs,\n",
    "                    verbose = 2, \n",
    "                    callbacks = [es],\n",
    "                    validation_data = (val_X, val_Y))\n",
    "    \n",
    "    model.evaluate(val_X, val_Y, verbose=1)\n",
    "    \n",
    "    pred_Y=model.predict(test_X)\n",
    "\n",
    "    tesst_Y=np.argmax(test_Y, axis=1)\n",
    "    pred_Y=np.argmax(pred_Y,axis=1)\n",
    "\n",
    "    cmatrix=confusion_matrix(tesst_Y, pred_Y)\n",
    "    cmatrix = cmatrix.astype('float')/cmatrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cmatrix, annot=True, fmt= '.2f', cmap=plt.cm.Blues)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272181fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e68d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75b8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a807fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b74ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
